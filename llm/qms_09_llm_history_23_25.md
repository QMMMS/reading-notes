# LLM 发展(2023~2025)

## GPT4

2023年基线：GPT-4范式。

在2023年初，LLM领域的发展遵循着一条清晰而有力的轨迹，规模决定能力，所以当年的爆火词就是Scaling Laws，更大的参数，更大的计算量，更大的数据规模。

这一理念的顶峰体现便是OpenAI的GPT-4，作为2023年当时最先进的AI，GPT-4被呈现为一个大规模的典范，基础架构依然是Transformer，但是拉长参数量，看上去就可以很好的work。尤其它在多种专业和学术基准测试中展现出与人类相当的水平，例如在模拟律师资格考试中取得了排名前10%的成绩，而前身GPT-3.5的得分则位于后10%。并且上下文窗口长度的极大扩展，提供了8K和32K两种规格的上下文长度，远超前代的4K和2K，有点像当年软盘时代，内存从1K到1M的变化。

> **不过GPT-4的发布也让OpenAI有了个别名，CloseAI，就是因为架构保密。**在技术报告中，OpenAI明确表示，出于竞争格局和大规模模型的安全影响的考量，将不提供关于架构（包括模型参数大小）、硬件、训练计算量、数据集构建或训练方法的任何细节。这个决定引发了社区关于透明度的广泛讨论，也使得外界对内部工作原理的理解主要依赖于间接推测和性能分析。当时一直有说法GPT-4拥有高达1760B的巨大参数量，但这从未得到官方证实，可它进一步强化了当时业界普遍持有的 Scaling-is-all-you-need 的信念，当时很多说法都是 GPU集群/数据量/更大的参数量 is all you need。

GPT-4的成功，给整个领域指明了一条通过不断扩大模型规模和数据量来提升智能水平的路径。

## 唯参数规模论时代的终结

随后到2024年，直到年底，一年多的时间该挖的数据、该买的算力、该请的人才都到位了，但还没出现GPT5，唯规模论的范式，迎来了深刻反思和系统性挑战**。**这一时期的模型演进并非由单一技术突破驱动，而是源于对现有范式局限性的多方面冲击。

1. **对效率的迫切需求**：传统Transformer架构的注意力机制具有与序列长度成 $$O(L^2)$$ 计算复杂度，加之密集型（Dense）模型高昂的推理成本，共同构成了一个严重的性能瓶颈。这极大地限制了上下文长度的扩展和模型的实际部署，从而催生了对稀疏架构和新型注意力机制的迫切需求。
2. **对推理的迫切需求**：业界逐渐认识到，单纯的规模扩张并不能赋予模型强大的、多步骤的逻辑推理能力。模型在面对需要复杂规划和逻辑演绎的任务时，依然表现不佳。这一瓶颈促使研究方向发生根本性转变，从完全依赖预训练阶段的计算投入，转向在推理阶段分配额外计算资源，即思考（thinking）模型的诞生。
3. **智能体的迫切需求**：随着模型推理能力的增强，下一个重点目标是让模型能够根据推理结果采取行动。这要求模型不仅能思考，还能与外部工具和环境进行交互，从而执行复杂任务，这标志着智能体AI（Agentic AI）时代的产生。

这三者有相互关联的驱动力，并非孤立存在，而是构成了一条紧密相连的因果链，清晰地勾勒出2023至2025年间前沿模型架构的演进脉络。**效率的提升是实现经济可行的推理模型的前提，而强大的推理能力则是构建有效智能体的基石**。

## MoE

[混合专家](https://qmmms.gitbook.io/note/llm/qms_12_deepseek#moe)（Mixture-of-Experts, MoE）架构是这一时期应对效率挑战最核心的策略之一，基本思想是用大量小型的专家网络替换Transformer中密集的、计算量巨大的前馈网络（FFN）层。

DeepSeek是推广和开源MoE架构的重要部分，从V2开始，到R1等系列模型清晰地展示了MoE架构的演进和威力，到现在基本全是MoE的模型。

- DeepSeek-V2：该模型引入了名为`DeepSeekMoE`的稀疏MoE架构。在236B（2360亿）参数的版本中，每个token仅激活21B（210亿）参数。这展示了超过10:1的总参数与激活参数之比，是MoE理念的经典体现，**这种设计使得模型能够在保持巨大知识容量的同时，显著降低推理成本。**  
- DeepSeek-V2-Lite：为了便于学术研究和更广泛的部署，DeepSeek推出了16B参数的轻量版MoE模型，每个token仅激活2.4B参数。其技术报告详细说明了其实现方式：除了第一层外，所有FFN层都被MoE层取代。每个MoE层包含2个所有token共享的专家（shared experts）和64个路由选择的专家（routed experts），每次会为每个token激活6个路由专家。这种细粒度的设计（共享专家处理通用模式，路由专家处理特定子问题）展示了MoE架构的灵活性和复杂性。  
- DeepSeek R1**：**作为一款专为推理设计的模型，R1同样基于MoE架构。它有惊人的671B总参数，而每个token的激活参数量为37B，**这其实进一步证明了MoE架构是实现数千亿级别参数模型的可行路径，尤其是在HPC（高性能计算）协同设计的加持下。** 

**Qwen3**系列同时提供了密集模型（最高32B）和MoE模型（如30B-A3B，235B-A22B）。

- 密集模型通常具有更可预测的性能和更简单的微调流程，适合寻求稳定性的企业用户。
- MoE模型则代表了技术前沿，以极致的规模和性能吸引高端用户和研究者

Minimax的**m1**模型也采用了混合MoE架构，拥有32个专家。模型总参数量为456B，每个token激活45.9B参数。这再次印证了约10:1的总参数与激活参数之比，已成为大型MoE模型的一个行业基准

## 注意力

新的注意力机制则旨在攻克Transformer架构的另一个核心瓶颈，自注意力机制（self-attention）与序列长度L的二次方计算复杂度 $$O(L^2)$$ ，这一瓶颈是限制模型处理超长上下文（如百万级token）的主要障碍。  

DeepSeek的**Multi-Head Latent Attention (MLA)**，通过将长序列的Key和Value向量（即KV缓存）压缩成一个单一的、低秩的潜在向量（latent vector）来解决KV缓存瓶颈。

Minimax-m1采用了的混合注意力方案。大部分Transformer层使用的是一种名为闪电注意力（Lightning Attention）的线性复杂度（O(L)）机制。然而，为了防止模型表达能力和性能的过度损失，架构中每隔七个使用线性注意力的Transformer块，就会插入一个使用标准softmax注意力的完整Transformer块。  是一种在效率和性能之间进行权衡的设计。  

Qwen2.5 架构中集成了**分组查询注意力（Grouped Query Attention, GQA）**，用于在性能和效率之间取得平衡。  

开源模型不断拉低标准推理服务的价格，迫使闭源领导者必须持续创新，推出新的、能证明高昂定价和专有性质的尖端功能。

## 思维链

CoT范式将计算开销的重心从预训练阶段部分转移到了推理阶段。核心理念是，**模型在生成最终答案之前，花费额外的计算资源来生成一段内部的思考链**（CoT，chain of thought）

OpenAI的o系列（o1, o3, o4-mini）是这一范式的开创者，它们在回答问题前会明确地花费时间进行Thinking。这个过程会生成一个长的、对用户隐藏的思考链，这段内部独白对于模型推导出正确答案至关重要。OpenAI以安全和竞争优势为由，禁止用户探查这个思考链。  

Anthropic的Claude 3.7是首个以“混合推理模型”（hybrid reasoning model）为卖点的模型，它允许用户在快速响应和更深度的“扩展思考”（extended thinking）之间进行选择。随后的Claude 4（Opus和Sonnet版本）进一步将此功能完善为两种明确的模式，允许开发者根据具体应用场景，在延迟和准确性之间做出权衡。 

Gemini 2.5 pro preview 0605是最近的屠榜模型

Qwen3 同样引入了“思考”和“非思考”模式，并在API中直接提供了一个名为思考预算（thinking budget）的参数。思考模式专用于处理复杂的逻辑、数学和编码任务，而非思考模式则用于高效的通用聊天。

## 强化学习

强化学习（RL）的角色在这一时期发生了根本性的转变。它不再仅仅是用于对话对齐（如RLHF）的工具 ，而是成为了教授模型如何进行推理的核心方法，推理时间也成为了新的Scaling Laws。

Thinking范式的出现，为扩展AI性能引入了一个全新的、正交的轴线：推理时计算。之前，AI的进步主要沿着训练时计算和参数数量这两个轴线来衡量。主流的假设是，用更多数据训练一个更大的模型，它就会变得更聪明。这是2024年之前的旧轴线。然而，o系列及同类模型证明，对于一组固定的模型权重，通过增加推理期间使用的计算量，可以极大地提升模型在复杂任务上的表现。

- 对**推理硬件**的需求将大规模增长，而不仅仅是训练硬件。运行一次查询的成本不再是固定的，而是根据问题的难度动态变化，这为硬件市场带来了新的增长点。
- 研究重点从单纯地扩大预训练规模，转向开发更高效的**推理算法**（如在思考链中进行更优的搜索或规划）和更有效的RL技术来引导推理过程。

DeepSeek-R1的训练过程是一个以RL为中心的多阶段流程。在通过SFT（监督微调）进行Cold Start后，模型会进入一个大规模的RL阶段，该阶段专注于基于规则的评估任务，以激励模型生成准确且结构清晰的推理过程。此后，再进行更多的SFT和一个最终用于通用对齐的RL阶段。

Minimax为训练大型模型开发了一种新颖的RL算法CISPO（Clipping Importance Sampling Policy Optimization），这个也是GRPO的变体，算法通过裁剪重要性采样权重而非使用信任域约束来稳定训练过程。  

## tool use

下一步就是让它能够通过与外部工具交互来执行计划。这正是AI智能体的定义。

OpenAI的o3和o4-mini是首批被描述为具备“智能体工具使用”（agentic tool use）能力的模型。例如，模型可以多次搜索网页，分析返回结果，并根据分析动态调整后续策略。

Anthropic的Claude 4的发布伴随着一套专为构建智能体而设计的新API功能：一个代码执行Sandbox、一个用于访问本地文件的Files API和一个MCP工具。这些功能，再结合独特的“计算机使用”（computer use）能力（即生成鼠标和键盘操作），使Claude成为构建能够与数字信息和图形用户界面（UI）进行交互的强大智能体的理想平台，目前Claude Code也给Cursor这些带来很大的危机感。

## Benchmark

**传统的NLP基准测试，如MMLU（大规模多任务语言理解），正迅速变得饱和**，对于区分前沿模型的能力越来越有限。与此同时，**一类专注于复杂推理（如GPQA, AIME）和智能体执行（如SWE-bench, Terminal-bench）的新基准，已成为衡量SOTA的真正标准。**

2025年AI指数报告明确指出了MMLU、GSM8K和HumanEval等传统AI基准的饱和。作为回应，学术界和工业界将注意力转向了能够有效测试新一代推理能力的基准。AIME（高难度数学竞赛）、GPQA（需要研究生水平知识的问答）以及特别是SWE-bench（要求模型像软件工程师一样修复真实的GitHub问题），现在已成为Claude 4、o3和DeepSeek-R1等模型发布公告中反复引用的事实标准。

## 未来？

**具身智能与世界模型**

当前在推理和智能体方面的趋势，是通向具身智能（Embodied AI）的直接前导。是模型从控制软件工具迈向控制机器人执行器的第一步。 核心挑战在于将模型从数字世界迁移到物理世界。物理世界施加了严格的实时约束，而当前LLM的顺序执行、逐帧处理的架构并非为此设计。未来的研究，如`Corki`框架所提出的，将致力于算法与硬件的协同设计，通过让LLM预测未来的运动轨迹而非单一的、离散的动作，来解耦高延迟的LLM推理与低延迟的机器人控制。这预示着“世界模型”（World Models）——即能够理解和预测物理世界动态的AI系统将成为下一个研究热点。  

------

**Transformer架构的探索**

尽管Transformer架构在过去几年取得了辉煌的成功，但固有的局限性也日益凸显，例如在处理某些组合性推理任务时的困难以及二次方复杂度问题。因此，学术界和工业界正在积极探索替代方案，尽管目前还没有任何架构能够完全取代它。

这些探索包括状态空间模型（State Space Models, SSMs），但研究表明，与Transformer相比，SSMs在需要从上下文中复制信息等任务上存在不足。目前，**大多数所谓的“后Transformer”研究，实际上更侧重于改进而非取代Transformer**。例如，通过提出新的层归一化方案（如`ResiDual`）来稳定深度Transformer的训练 ，或者开发更高效的长上下文处理方法 ，这些都是在现有范式内的增量创新。
